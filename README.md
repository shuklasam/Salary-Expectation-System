# Salary Expectation Analysis ğŸ’°

A comprehensive machine learning project that predicts salary expectations using multiple regression models and advanced analysis techniques. This project demonstrates the application of various regression algorithms to understand and forecast compensation trends.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Models Implemented](#models-implemented)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Results & Analysis](#results--analysis)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project implements a salary expectation prediction system that analyzes compensation data using six different regression models. The system provides insights into salary trends and generates accurate predictions based on various features such as experience, education, location, and other relevant factors.

Additionally, the project includes a **startup profit analysis** component using Multiple Linear Regression to understand the factors influencing startup profitability.

## âœ¨ Features

- **Multiple Regression Models**: Implementation of 6 different regression techniques for comprehensive analysis
- **Comparative Analysis**: Side-by-side comparison of model performance metrics
- **Data Visualization**: Rich visualizations using Matplotlib and Seaborn for insights
- **Feature Engineering**: Advanced data preprocessing and feature extraction
- **Model Evaluation**: Comprehensive evaluation metrics including RÂ², RMSE, and MAE
- **Interactive Notebooks**: Jupyter Notebook implementation for exploratory analysis
- **Startup Profit Prediction**: Specialized analysis for startup financial forecasting

## ğŸ› ï¸ Tech Stack

### Core Libraries

- **NumPy**: Numerical computing and array operations
- **Pandas**: Data manipulation and analysis
- **Scikit-learn**: Machine learning algorithms and tools

### Visualization

- **Matplotlib**: Static plotting and visualization
- **Seaborn**: Statistical data visualization

### Environment

- **Jupyter Notebook**: Interactive development and analysis

## ğŸ¤– Models Implemented

### 1. Linear Regression
Simple linear approach for baseline predictions and understanding linear relationships between features and salary.

### 2. Polynomial Regression
Captures non-linear relationships by transforming features into polynomial terms.

### 3. Support Vector Regression (SVR)
Utilizes support vector machines for regression tasks, effective for complex, non-linear patterns.

### 4. Decision Tree Regression
Tree-based model that captures non-linear relationships through hierarchical decision rules.

### 5. Random Forest Regression
Ensemble method combining multiple decision trees for robust predictions and reduced overfitting.

### 6. Multiple Linear Regression
Multi-variable regression for startup profit analysis, examining relationships between multiple independent variables and profitability.

## ğŸ“¦ Installation

### Prerequisites

- Python 3.7 or higher
- pip package manager

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/salary-expectation.git
cd salary-expectation
```

2. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

### Dependencies

```txt
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=0.24.0
jupyter>=1.0.0
```

## ğŸš€ Usage

### Running the Notebooks

1. Start Jupyter Notebook:
```bash
jupyter notebook
```

2. Navigate to the notebooks directory and open the desired analysis file:
   - `linear_regression.ipynb` - Basic linear regression analysis
   - `polynomial_regression.ipynb` - Polynomial feature analysis
   - `svr_analysis.ipynb` - Support Vector Regression
   - `decision_tree_regression.ipynb` - Decision tree implementation
   - `random_forest_regression.ipynb` - Random forest ensemble method
   - `startup_profit_analysis.ipynb` - Multiple linear regression for startups

3. Run cells sequentially to perform analysis and generate predictions

### Quick Start Example

```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

# Load data
data = pd.read_csv('data/salary_data.csv')

# Prepare features and target
X = data[['experience', 'education', 'location']]
y = data['salary']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f'RÂ² Score: {r2:.4f}')
print(f'RMSE: {rmse:.2f}')
```

## ğŸ“ Project Structure

```
salary-expectation/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ salary_data.csv
â”‚   â””â”€â”€ startup_data.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ linear_regression.ipynb
â”‚   â”œâ”€â”€ polynomial_regression.ipynb
â”‚   â”œâ”€â”€ svr_analysis.ipynb
â”‚   â”œâ”€â”€ decision_tree_regression.ipynb
â”‚   â”œâ”€â”€ random_forest_regression.ipynb
â”‚   â””â”€â”€ startup_profit_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ model_comparisons.png
â”‚   â””â”€â”€ predictions.csv
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

## ğŸ“Š Results & Analysis

### Model Performance Comparison

| Model | RÂ² Score | RMSE | MAE |
|-------|----------|------|-----|
| Linear Regression | 0.XX | XXX | XXX |
| Polynomial Regression | 0.XX | XXX | XXX |
| SVR | 0.XX | XXX | XXX |
| Decision Tree | 0.XX | XXX | XXX |
| Random Forest | 0.XX | XXX | XXX |
| Multiple Linear (Startup) | 0.XX | XXX | XXX |

### Key Insights

- **Random Forest** typically provides the most robust predictions with lowest variance
- **Polynomial Regression** captures non-linear salary growth patterns effectively
- **SVR** performs well with high-dimensional feature spaces
- **Decision Tree** offers interpretable results but may overfit without pruning
- **Multiple Linear Regression** effectively identifies key profit drivers for startups

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Contribution Guidelines

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¤ Author

Samarth Shukla

## ğŸ™ Acknowledgments

- Dataset sources and contributors
- Scikit-learn documentation and community
- Inspiration from industry salary analysis research


â­ If you found this project helpful, please consider giving it a star!

**Happy Analyzing!** ğŸ“ˆ
